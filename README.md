# Awesome Treasure of Large Language Models Collection

![](https://raw.githubusercontent.com/ashishpatel26/Treasure-of-Transformers/main/images/tot.jpg)

![fw.jpg](https://github.com/ashishpatel26/Treasure-of-Transformers/blob/main/images/fw.jpg?raw=true)

---

###  üßë‚Äçüíªüë©‚ÄçüíªCollection of All LLMs algorithm list with Code üßë‚Äçüíªüë©‚Äçüíª![Jupyter Notebook](https://img.shields.io/badge/jupyter-%23FA0F00.svg?style=for-the-badge&logo=jupyter&logoColor=white)

---

| Sr No | Algorithm Name                                               | Year | Blog                                                         | Video                                                        | Official Repo                                                | Code                                                         |
| ----- | ------------------------------------------------------------ | ---- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 1     | [GPT-Neo](https://github.com/EleutherAI/gpt-neo)             | 2021 | [![](https://raw.githubusercontent.com/ashishpatel26/Treasure-of-Transformers/main/images/b1.jpg)](https://bit.ly/3rYanJk) | [![Youtube](https://raw.githubusercontent.com/ashishpatel26/Treasure-of-Transformers/main/images/yt1.jpg)](https://youtu.be/6MI0f6YjJIk) | [![](https://raw.githubusercontent.com/ashishpatel26/Treasure-of-Transformers/main/images/git.jpg)](https://github.com/EleutherAI/gpt-neo) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/EleutherAI/GPTNeo/blob/master/GPTNeo_example_notebook.ipynb) |
| 2     | [Transformer](https://arxiv.org/abs/1706.03762v5)            | 2017 | [![](https://raw.githubusercontent.com/ashishpatel26/Treasure-of-Transformers/main/images/b1.jpg)](https://bit.ly/3DNsrIp) | [![Youtube](https://raw.githubusercontent.com/ashishpatel26/Treasure-of-Transformers/main/images/yt1.jpg)](https://youtu.be/iDulhoQ2pro) | [![](https://raw.githubusercontent.com/ashishpatel26/Treasure-of-Transformers/main/images/git.jpg)](https://github.com/tensorflow/models/tree/master/official/nlp/transformer) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/bentrevett/pytorch-seq2seq/blob/master/6%20-%20Attention%20is%20All%20You%20Need.ipynb) |
---

#### Instruction

* All blogs have links and some links contains different languages blog such as Chinese, Korean etc. for this Please use [Google Tranlater Page Convert](https://chrome.google.com/webstore/detail/google-translate/aapbdbdomjkkjkaonfhkkikfgjllcleb?hl=en).

---

#### How to Contribute

---

if you want to contribute on this project please send us email on : ashishpatel.ce.2011@gmail.com or chetanraj002@gmail.com. 

üôèüôèSpecial Thanks to [**Ashish Patel**](https://github.com/ashishpatel26) for contributing.

---

Copyright for source code belongs to the original author(s). However, under fair use you are encouraged to fork and contribute minor corrections and updates for the benefit of the reader(s).

---

**_Thanks for  Reading ...!!!_**

---
