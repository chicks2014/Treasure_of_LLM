# Awesome Treasure of Large Language Models Collection

![main_poster.jpg](images/main_poster.jpg)

image source: https://arxiv.org/pdf/2304.13712.pdf

![fw.jpg](/images/fw.jpg)

---

###  üßë‚Äçüíªüë©‚ÄçüíªCollection of All LLMs algorithm list with Code üßë‚Äçüíªüë©‚Äçüíª![Jupyter Notebook](https://img.shields.io/badge/jupyter-%23FA0F00.svg?style=for-the-badge&logo=jupyter&logoColor=white)

---

| Sr No | Algorithm Name                                               | Year | Blog                                                         | Video                                                        | Official Repo                                                | Code                                                         |
| ----- | ------------------------------------------------------------ | ---- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 1     | [Awesome-LLM](https://github.com/Hannibal046/Awesome-LLM)             | 2023 | [![](./images/b1.jpg)](https://bit.ly/3rYanJk) | [![Youtube](./images/yt1.jpg)](https://youtu.be/6MI0f6YjJIk) | [![](images/git.jpg)](https://github.com/Hannibal046/Awesome-LLM) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/EleutherAI/GPTNeo/blob/master/GPTNeo_example_notebook.ipynb) |
| 2     | [Awesome-LLMOps](https://github.com/tensorchord/Awesome-LLMOps)            | 2023 | [![](./images/b1.jpg)](https://bit.ly/3DNsrIp) | [![Youtube](./images/yt1.jpg)](https://youtu.be/iDulhoQ2pro) | [![](./images/git.jpg)](https://github.com/tensorchord/Awesome-LLMOps) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/bentrevett/pytorch-seq2seq/blob/master/6%20-%20Attention%20is%20All%20You%20Need.ipynb) |
| 3     | [Dolly](https://github.com/databrickslabs/dolly)            | 2023 | [![](./images/b1.jpg)](https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html) | [![Youtube](./images/yt1.jpg)](https://www.youtube.com/watch?v=GpWqjNf0SCM) | [![](./images/git.jpg)](https://github.com/databrickslabs/dolly) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/bentrevett/pytorch-seq2seq/blob/master/6%20-%20Attention%20is%20All%20You%20Need.ipynb) |
| 4     | [Bloom](https://github.com/huggingface/transformers-bloom-inference)            | 2023 | [![](./images/b1.jpg)](https://github.com/huggingface/blog/blob/main/bloom-inference-pytorch-scripts.md) | [![Youtube](./images/yt1.jpg)](https://www.youtube.com/watch?v=ZHx0TsYB3ac) | [![](./images/git.jpg)](https://github.com/huggingface/transformers-bloom-inference) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/bentrevett/pytorch-seq2seq/blob/master/6%20-%20Attention%20is%20All%20You%20Need.ipynb) |
| 5     | [Vicu√±a](https://github.com/eddieali/Vicuna-AI-LLM)            | 2023 | [![](./images/b1.jpg)](https://lmsys.org/blog/2023-03-30-vicuna/) | [![Youtube](./images/yt1.jpg)](https://www.youtube.com/watch?v=ByV5w1ES38A) | [![](./images/git.jpg)](https://lmsys.org/blog/2023-03-30-vicuna/) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/bentrevett/pytorch-seq2seq/blob/master/6%20-%20Attention%20is%20All%20You%20Need.ipynb) |
| 6     | [Alpaca](https://github.com/tatsu-lab/stanford_alpaca)            | 2023 | [![](./images/b1.jpg)](https://crfm.stanford.edu/2023/03/13/alpaca.html) | [![Youtube](./images/yt1.jpg)](https://youtu.be/D-clHgmaKKU) | [![](./images/git.jpg)](https://github.com/tatsu-lab/stanford_alpaca) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/bentrevett/pytorch-seq2seq/blob/master/6%20-%20Attention%20is%20All%20You%20Need.ipynb) |
| 7     | [LLaMA](https://github.com/facebookresearch/llama)            | 2023 | [![](./images/b1.jpg)](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/) | [![Youtube](./images/yt1.jpg)](https://www.youtube.com/watch?v=BKb_AnREvvY) | [![](./images/git.jpg)](https://github.com/facebookresearch/llama) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/bentrevett/pytorch-seq2seq/blob/master/6%20-%20Attention%20is%20All%20You%20Need.ipynb) |
| 8     | [GPT4All](https://github.com/nomic-ai/gpt4all)            | 2023 | [![](./images/b1.jpg)](https://towardsai.net/p/machine-learning/llama-gpt4all-simplified-local-chatgpt) | [![Youtube](./images/yt1.jpg)](https://www.youtube.com/watch?v=rOa0wy2TDYE) | [![](./images/git.jpg)](https://github.com/nomic-ai/gpt4all) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/bentrevett/pytorch-seq2seq/blob/master/6%20-%20Attention%20is%20All%20You%20Need.ipynb) |

---

#### Instruction

* All blogs have links and some links contains different languages blog such as Chinese, Korean etc. for this Please use [Google Tranlater Page Convert](https://chrome.google.com/webstore/detail/google-translate/aapbdbdomjkkjkaonfhkkikfgjllcleb?hl=en).

---

#### How to Contribute

---

if you want to contribute on this project please send us email on : chetanraj002@gmail.com or ashishpatel.ce.2011@gmail.com. 

üôèüôèSpecial Thanks to [**Ashish Patel**](https://github.com/ashishpatel26) for contributing.

---

Copyright for source code belongs to the original author(s). However, under fair use you are encouraged to fork and contribute minor corrections and updates for the benefit of the reader(s).

---

**_Thanks for  Reading ...!!!_**

---
