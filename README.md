# Awesome Treasure of Large Language Models Collection

![](https://github.com/chicks2014/Treasure_of_LLM/blob/d210e63a760dd8fc105ea2846f3f4c759cf0bfb6/main_poster.jpg)
image source: https://arxiv.org/pdf/2304.13712.pdf

![fw.jpg](https://github.com/ashishpatel26/Treasure-of-Transformers/blob/main/images/fw.jpg?raw=true)
---

###  üßë‚Äçüíªüë©‚ÄçüíªCollection of All LLMs algorithm list with Code üßë‚Äçüíªüë©‚Äçüíª![Jupyter Notebook](https://img.shields.io/badge/jupyter-%23FA0F00.svg?style=for-the-badge&logo=jupyter&logoColor=white)

---

| Sr No | Algorithm Name                                               | Year | Blog                                                         | Video                                                        | Official Repo                                                | Code                                                         |
| ----- | ------------------------------------------------------------ | ---- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 1     | [Awesome-LLM](https://github.com/Hannibal046/Awesome-LLM)             | 2023 | [![](https://raw.githubusercontent.com/ashishpatel26/Treasure-of-Transformers/main/images/b1.jpg)](https://bit.ly/3rYanJk) | [![Youtube](https://raw.githubusercontent.com/ashishpatel26/Treasure-of-Transformers/main/images/yt1.jpg)](https://youtu.be/6MI0f6YjJIk) | [![](https://raw.githubusercontent.com/ashishpatel26/Treasure-of-Transformers/main/images/git.jpg)](https://github.com/Hannibal046/Awesome-LLM) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/EleutherAI/GPTNeo/blob/master/GPTNeo_example_notebook.ipynb) |
| 2     | [Awesome-LLMOps](https://github.com/tensorchord/Awesome-LLMOps)            | 2023 | [![](https://raw.githubusercontent.com/ashishpatel26/Treasure-of-Transformers/main/images/b1.jpg)](https://bit.ly/3DNsrIp) | [![Youtube](https://raw.githubusercontent.com/ashishpatel26/Treasure-of-Transformers/main/images/yt1.jpg)](https://youtu.be/iDulhoQ2pro) | [![](https://raw.githubusercontent.com/ashishpatel26/Treasure-of-Transformers/main/images/git.jpg)](https://github.com/tensorchord/Awesome-LLMOps) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/bentrevett/pytorch-seq2seq/blob/master/6%20-%20Attention%20is%20All%20You%20Need.ipynb) |
| 3     | [Dolly](https://github.com/databrickslabs/dolly)            | 2023 | [![](https://raw.githubusercontent.com/ashishpatel26/Treasure-of-Transformers/main/images/b1.jpg)](https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html) | [![Youtube](https://raw.githubusercontent.com/ashishpatel26/Treasure-of-Transformers/main/images/yt1.jpg)](https://www.youtube.com/watch?v=GpWqjNf0SCM) | [![](https://raw.githubusercontent.com/ashishpatel26/Treasure-of-Transformers/main/images/git.jpg)](https://github.com/databrickslabs/dolly) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/bentrevett/pytorch-seq2seq/blob/master/6%20-%20Attention%20is%20All%20You%20Need.ipynb) |
| 4     | [Bloom](https://github.com/huggingface/transformers-bloom-inference)            | 2023 | [![](https://raw.githubusercontent.com/ashishpatel26/Treasure-of-Transformers/main/images/b1.jpg)](https://github.com/huggingface/blog/blob/main/bloom-inference-pytorch-scripts.md) | [![Youtube](https://raw.githubusercontent.com/ashishpatel26/Treasure-of-Transformers/main/images/yt1.jpg)](https://www.youtube.com/watch?v=ZHx0TsYB3ac) | [![](https://raw.githubusercontent.com/ashishpatel26/Treasure-of-Transformers/main/images/git.jpg)](https://github.com/huggingface/transformers-bloom-inference) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/bentrevett/pytorch-seq2seq/blob/master/6%20-%20Attention%20is%20All%20You%20Need.ipynb) |
---

#### Instruction

* All blogs have links and some links contains different languages blog such as Chinese, Korean etc. for this Please use [Google Tranlater Page Convert](https://chrome.google.com/webstore/detail/google-translate/aapbdbdomjkkjkaonfhkkikfgjllcleb?hl=en).

---

#### How to Contribute

---

if you want to contribute on this project please send us email on : ashishpatel.ce.2011@gmail.com or chetanraj002@gmail.com. 

üôèüôèSpecial Thanks to [**Ashish Patel**](https://github.com/ashishpatel26) for contributing.

---

Copyright for source code belongs to the original author(s). However, under fair use you are encouraged to fork and contribute minor corrections and updates for the benefit of the reader(s).

---

**_Thanks for  Reading ...!!!_**

---
